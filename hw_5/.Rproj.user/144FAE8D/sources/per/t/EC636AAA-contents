library(Rfacebook)
library(NLP)

library(tm)
library(RColorBrewer)
library(wordcloud)
#library(jiebaRD)
#library(jiebaR)

page.id<-"22092443056"
token<-"EAACEdEose0cBAJfDteCwPgpzALAfThhTGqRkA94p58WZCLtSwmth5cXGfn4OUfHa0TzHYa5Ea7sHCVtalqCfL9tpSv1btsfNe8YGpBFV8Tm5XMMqirj6hJ7aVUuQLIMowkeG6IpqINJm3n5JxWpC3JEijuqg93y1xfjye4JE6jH4v2LpHZAqYOEMOUDQnwfjPfZCIXF9wZDZD"
page<-getPage(page.id,token, n=300)

doc01<-Corpus(VectorSource(page$message))
inspect(doc01)

## Hope to delete unnecessary characters but failed

#doc02 <- gsub("[^0-9A-Za-z///' ]","'" , doc01 ,ignore.case = TRUE)
#x <- "a1~!@#$%^&*(){}_+:\"<>?,./;'[]-=" #or whatever
#str_replace_all(x, "[[:punct:]]", " ")



#要清洗掉的東西
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))

#定義清洗：清洗就是把你找到的符號用空白取代
#doc02<- tm_map(doc01, toSpace, "<U+00AF>")
doc02<- tm_map(doc01, toSpace, ">")
inspect(doc02[c(5:10)])

#doc02<- tm_map(doc02, toSpace, "<U+")
##problem at this command
###doc02<- tm_map(doc02, toSpace, "+")

doc02<- tm_map(doc02, toSpace, "#")
inspect(doc02[c(5:10)])

doc02<- tm_map(doc02, toSpace, "<U+00AF>")
doc02<- tm_map(doc02, toSpace, ">")
doc02<- tm_map(doc02, toSpace, "<U+")
doc02<- tm_map(doc02, toSpace, "#")
doc02<- tm_map(doc02, toSpace, "/")
doc02<- tm_map(doc02, toSpace, "@")
doc02<- tm_map(doc02, toSpace,"<NA>")
doc02<- tm_map(doc02, toSpace,"~")

inspect(doc02[c(5:10)])

# second round clean-up after term-document matrix
doc02<- tm_map(doc02, toSpace, "the")
doc02<- tm_map(doc02, toSpace, "and")
doc02<- tm_map(doc02, toSpace,"for")
doc02<- tm_map(doc02, toSpace,"you")
doc02<- tm_map(doc02, toSpace,"http")
doc02<- tm_map(doc02, toSpace,"with")
doc02<- tm_map(doc02, toSpace,"sbuxco")

#remove punctuation and others
doc02<-tm_map(doc02,removePunctuation,ucp=TRUE)
doc02<-tm_map(doc02,removeNumbers)
doc02<-tm_map(doc02,stripWhitespace)
doc02<-tm_map(doc02,content_transformer(tolower))
#remove english common stopwords
doc02<- tm_map(doc02,removeWords,stopwords("english"))

inspect(doc02[c(1:10)])

##build a term-document matrix
dtm<-TermDocumentMatrix(doc02)
m<-as.matrix(dtm)
v<-sort(rowSums(m),decreasing=TRUE)
d<-data.frame(word=names(v),freq=v)
head(d,20)


##noticed some useless words, clean it up again
##add lines 52-58

##WordCloud
set.seed(1234)
wordcloud(words=d$word,freq=d$freq,min.freq=2,max.words = 200,random.order = FALSE,
          rot.per = 0.35,colors=brewer.pal(8,"Dark2"))

#----4 apr 18-----#
library(Rfacebook)
library(NLP)
library(dplyr)
library(tm)
library(RColorBrewer)

page.id<-"22092443056"
token<-"EAACEdEose0cBAFBtCjxMZAMOOyApc8thB0BwlQVhodBUr3hPUoXfoZA2YkHaB8rAZCamp8xiwKI9Igmp5ucuq87RrzslM772fEWkrsTegjRK0BMYUthlp1LwlhAj7yZBZCBdHXrWJssol7F1hCDqvlZByQs87bKbtDOtGZAt6Y4ZCyqFbni05qnvZAZCOlSRskeqEZD"
page040418<-getPage(page.id,token, n=300)

doc040418<-Corpus(VectorSource(page040418$message))
inspect(doc040418[1:3])
inspect(doc01[1:3])
##------------5 apr 18---------------##
library(Rfacebook)
library(NLP)
library(dplyr)
library(tm)
library(RColorBrewer)

page.id<-"22092443056"
token<-"EAACEdEose0cBAHpZAi3VjTfdVbkSP0MvELuojsyU6SGeLMevH4iYrMEZAdVQ5xZC5Jhuv0cjaFwOJTlhFgWzRUhFXLETC6CJg180L27DggeLHPUdh37U8xmWjuQpjmYfJkn8YIwvyG1jdMEtvKxeQSZAGPBiEZC9LK8AnjDtSlZCCwin0Nie2PR5VTU8e1JyMZD"
page050418<-getPage(page.id,token, n=500)

doc050418<-Corpus(VectorSource(page050418$message))
inspect(doc050418)

## combine three pages first as data.frame##
str(page050418)
page050418_300<-page050418[c(1:300),]

#---1st try: combine into dataframe then convert into corpus, but need metadata--#
#origin:final<-data.frame(page$message,page040418$message,page050418[c(201:500),]$message)
##but the variable names are weird, so name the variables
final<-data.frame(apr03=page$message,apr04=page040418$message,apr05=page050418[c(201:500),]$message,stringsAsFactors = FALSE)
class(final$apr03)

#-- 2nd try: transfer each into vectorsource, then combine as a dataframesorce##
#a<-VectorSource(page$message)
#b<-VectorSource(page040418$message)
#c<-VectorSource(page050418$message)
#dfsource<-DataframeSource(c(a,b,c))

## then convert this dataset into VectorSource, then Corpus##
final_vec<-VectorSource(final) # cant use 'dataframesource', still don't know why
final_cor<-Corpus(final_vec)
inspect(final_cor)

#clean up data
##set a function by using gsub-- still struggling
#final_clean<-tm_map(final_cor,toSpace,"\\d+") # cant use this one, this cant fully remove the numbers
#final_clean<-tm_map(final_cor,toSpace,"00a1")

# clean data step by step
final_clean<-tm_map(final_cor,removePunctuation,ucp=TRUE)
final_clean<-tm_map(final_clean,stripWhitespace)
final_clean<-tm_map(final_clean,removeNumbers)
final_clean<-tm_map(final_clean,removeWords,stopwords("english"))
final_clean<-tm_map(final_clean,content_transformer(tolower))
class(final_clean)
#class is "corpus"

#final_clean<-gsub("<u+><u+fef>"," ",final_clean),cant use gsub, the class turns into character
#用gsub就會成為characters, 還是說corpus只能用tm_map
#a<-gsub("-"," ",final_clean)
#a<-gsub("="," ",final_clean)
#a<-gsub("+"," ",final_clean)
#a<-tm_map(final_clean,toSpace,"[a-z]{5}") #delete characters show up 5times insequence, don;t work


#class(a)


##try tospace, it works
final_clean<-tm_map(final_clean,toSpace,"-")
final_clean<-tm_map(final_clean,toSpace,"=")
final_clean<-tm_map(final_clean,toSpace,"\n")
final_clean<-tm_map(final_clean,toSpace,"<u+fef>")
final_clean<-tm_map(final_clean,toSpace,"<u+>")
final_clean<-tm_map(final_clean,toSpace,"<ed>")
final_clean<-tm_map(final_clean,toSpace,"<u+bd>")
final_clean<-tm_map(final_clean,toSpace,"<u+b>")
final_clean<-tm_map(final_clean,toSpace,"mmmm")


inspect(final_clean[2]) #check the 2nd one (i.e.040418)

#convert to term-document matrix, 'final_clean' has to be a corpus
class(final_clean) # a corpus
tdm<-TermDocumentMatrix(final_clean)
tdm_matrix<-as.matrix(tdm)


#directly convert corpus into TDM with tf-idf
tdm_tfidf<-TermDocumentMatrix(final_clean,control=list(weighting=function(x) weightTfIdf(x,normalize = FALSE)))
tdm_tfidf_matrix<-as.matrix(tdm_tfidf)

tdm_tfidf_try<-dissimilarity(final_clean, method="cosine")
#tdm_try<-TermDocumentMatrix(final_cor)
#tdm_try_ma<-as.matrix(tdm)
#class(tdm_try_ma[1,1])

class(tdm_matrix)
colSums(tdm_matrix)
order(rowSums(tdm_matrix))
